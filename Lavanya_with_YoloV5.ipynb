{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lavanyasatpute/lavanyasatpute/blob/main/Lavanya_with_YoloV5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp0ETijsZS3k",
        "outputId": "5269777f-9b54-43a3-b060-7ef6bf68fc87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16772, done.\u001b[K\n",
            "remote: Counting objects: 100% (313/313), done.\u001b[K\n",
            "remote: Compressing objects: 100% (230/230), done.\u001b[K\n",
            "remote: Total 16772 (delta 171), reused 159 (delta 83), pack-reused 16459\u001b[K\n",
            "Receiving objects: 100% (16772/16772), 15.49 MiB | 25.74 MiB/s, done.\n",
            "Resolving deltas: 100% (11474/11474), done.\n",
            "/content/yolov5\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.downloads import attempt_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI3q_fNoZg-H",
        "outputId": "1ea46761-41c2-49cd-80e4-2785dc0fa49a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.1/800.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSetup complete. Using torch 2.3.0+cu121 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15102MB, multi_processor_count=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q roboflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDE-eG4eZkt4",
        "outputId": "e5c16d45-9807-417d-bc92-66582f6e02d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m610.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Ht4ABPzUdkuooPVppqvl\")\n",
        "project = rf.workspace(\"rudra-fsiml\").project(\"skin-cancer-detection-sqagd\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbmskXxDZ5ky",
        "outputId": "8de3f3c1-b4dd-4eaa-88c8-691033734a7e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Skin-Cancer-Detection-2 to yolov5pytorch:: 100%|██████████| 184656/184656 [00:07<00:00, 25254.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Skin-Cancer-Detection-2 in yolov5pytorch:: 100%|██████████| 34194/34194 [00:04<00:00, 8240.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UzsOSSegaNtH",
        "outputId": "6514b792-8e4f-439a-a1d2-7af4baeed183"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/yolov5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.location"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Cx5cABLvaWYS",
        "outputId": "fbd0f0d0-40bc-4554-be68-56dda5ce0770"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/yolov5/Skin-Cancer-Detection-2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXYC8_Nzaa5w",
        "outputId": "bc1a237f-e52a-436c-d4ec-b521cdb7e041"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.location"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_r6zn0RvagB2",
        "outputId": "3567d238-77ed-4c86-e09f-a0e17942cb2d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/yolov5/Skin-Cancer-Detection-2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cat {dataset.location}/data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj7mRGI1aj5N",
        "outputId": "c0f18cce-904c-44e5-b6e3-d6c3aa7223c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names:\n",
            "- actinic_keratosis\n",
            "- basal_cell_carcinoma\n",
            "- melanoma\n",
            "- nevus\n",
            "nc: 4\n",
            "roboflow:\n",
            "  license: MIT\n",
            "  project: skin-cancer-detection-sqagd\n",
            "  url: https://universe.roboflow.com/rudra-fsiml/skin-cancer-detection-sqagd/dataset/2\n",
            "  version: 2\n",
            "  workspace: rudra-fsiml\n",
            "test: ../test/images\n",
            "train: Skin-Cancer-Detection-2/train/images\n",
            "val: Skin-Cancer-Detection-2/valid/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "metadata": {
        "id": "JN1G47_SasSi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CKzqt4zIa0FR",
        "outputId": "8f016ee2-b65e-4ef4-ae7b-e56b2dab7a29"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cat /content/yolov5/models/yolov5s.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9IUpK9Ja6Pu",
        "outputId": "2d508bff-875c-4c05-e784-f768ca6bcf50"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Ultralytics YOLOv5 🚀, AGPL-3.0 license\n",
            "\n",
            "# Parameters\n",
            "nc: 80 # number of classes\n",
            "depth_multiple: 0.33 # model depth multiple\n",
            "width_multiple: 0.50 # layer channel multiple\n",
            "anchors:\n",
            "  - [10, 13, 16, 30, 33, 23] # P3/8\n",
            "  - [30, 61, 62, 45, 59, 119] # P4/16\n",
            "  - [116, 90, 156, 198, 373, 326] # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [\n",
            "    [-1, 1, Conv, [64, 6, 2, 2]], # 0-P1/2\n",
            "    [-1, 1, Conv, [128, 3, 2]], # 1-P2/4\n",
            "    [-1, 3, C3, [128]],\n",
            "    [-1, 1, Conv, [256, 3, 2]], # 3-P3/8\n",
            "    [-1, 6, C3, [256]],\n",
            "    [-1, 1, Conv, [512, 3, 2]], # 5-P4/16\n",
            "    [-1, 9, C3, [512]],\n",
            "    [-1, 1, Conv, [1024, 3, 2]], # 7-P5/32\n",
            "    [-1, 3, C3, [1024]],\n",
            "    [-1, 1, SPPF, [1024, 5]], # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head: [\n",
            "    [-1, 1, Conv, [512, 1, 1]],\n",
            "    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n",
            "    [[-1, 6], 1, Concat, [1]], # cat backbone P4\n",
            "    [-1, 3, C3, [512, False]], # 13\n",
            "\n",
            "    [-1, 1, Conv, [256, 1, 1]],\n",
            "    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n",
            "    [[-1, 4], 1, Concat, [1]], # cat backbone P3\n",
            "    [-1, 3, C3, [256, False]], # 17 (P3/8-small)\n",
            "\n",
            "    [-1, 1, Conv, [256, 3, 2]],\n",
            "    [[-1, 14], 1, Concat, [1]], # cat head P4\n",
            "    [-1, 3, C3, [512, False]], # 20 (P4/16-medium)\n",
            "\n",
            "    [-1, 1, Conv, [512, 3, 2]],\n",
            "    [[-1, 10], 1, Concat, [1]], # cat head P5\n",
            "    [-1, 3, C3, [1024, False]], # 23 (P5/32-large)\n",
            "\n",
            "    [[17, 20, 23], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "metadata": {
        "id": "ET1LYxf9a_p8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]\n"
      ],
      "metadata": {
        "id": "ZoBwx7hcbJUL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 50 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5s.yaml --weights 'yolov5s.pt' --name yolov5s_results  --cache\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyWNIbjmbsVD",
        "outputId": "ef992840-314b-470b-8e61-7367096ade2b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "2024-07-12 09:32:32.549015: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-12 09:32:32.549067: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-12 09:32:32.664115: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/custom_yolov5s.yaml, data=/content/yolov5/Skin-Cancer-Detection-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-339-g150a1a31 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "custom_YOLOv5s summary: 233 layers, 7263185 parameters, 7263185 gradients\n",
            "\n",
            "Transferred 223/369 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 59 weight(decay=0.0), 70 weight(decay=0.0005), 62 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/Skin-Cancer-Detection-2/train/labels.cache... 12984 images, 0 backgrounds, 48 corrupt: 100% 13012/13012 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0000555_jpg.rf.1d5ad3f977387be2de499ca32d0f5d30.jpg: ignoring corrupt image/label: image size (10, 4) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0000555_jpg.rf.3c7a9e14e49cb2996f9537fb9273fc11.jpg: ignoring corrupt image/label: image size (10, 4) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0000555_jpg.rf.59c2f792e206578ea5b2e084a2d84e85.jpg: ignoring corrupt image/label: image size (8, 3) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0000555_jpg.rf.e8e72a38d3d50f6a92e618e27281166a.jpg: ignoring corrupt image/label: image size (8, 3) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010089_jpg.rf.9d8f306b1ce83e44d836afa0c6fdf2d2.jpg: ignoring corrupt image/label: image size (4, 4) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010089_jpg.rf.d75b53fffae81d22ca912910096005e8.jpg: ignoring corrupt image/label: image size (4, 4) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010609_jpg.rf.10a301a7e0e991158dc6200c62803dc4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     7.5057      5.3333]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010609_jpg.rf.9acb401fa42ca7358adc0ccc096753e8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.0318      5.4026]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010609_jpg.rf.c40c29eb6f940698aabd99e1c4a238ed.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.4026      5.6348]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010609_jpg.rf.e6e3ada94f949ab7f092a2148f38a948.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.3333      7.5057]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.0f855e49c9108e277cd8d3d34b074e4f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.2532      2.5326]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.146038e8eeefbc4cd1bf70a2cbf726f1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.1625      6.0832      1.0071]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.166df6d9c926c288a35d171e561007ed.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     3.0514      3.1093]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.1d8060c117adc64ec0b6a51b4a51d361.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       1.62      2.9722]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.5d5b45b7e9172526740f2c4ffe214d6b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     9.8375      6.9781      1.0071]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.84be58f2fd740829af2ff92ef6e25d98.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.6758      2.9314]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.9449a463b4bb1b45788a9afea0ea2bd5.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     3.3174      10.679       1.369]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.aa2ed708a7c53c1b8e25d5b87fa3e76b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.4307      2.3611]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.ae0949416026c043786d5f28bbf9c37a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.7975      2.8008]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.baffe2935ddd790c796d748768961ff7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.3749      2.4019]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.c3c8a9b3e508c26ab93e254278afef35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.2359       3.472]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.e679e8be364aa84cd7d78422f941a899.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.2478      8.7148       1.369]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.ebdf21b7e33ea705ee18c25c133c0c96.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     4.1396      2.3608]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010754_jpg.rf.ec45f9c1208e0cf0b05df797683f7fdd.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.2559      2.5093]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010834_jpg.rf.71618e2ad1214d6800b78e9de5411ba7.jpg: ignoring corrupt image/label: image size (4, 5) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0010834_jpg.rf.80351e1dd607ac9589f370a7f5758cf0.jpg: ignoring corrupt image/label: image size (4, 5) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0025644_jpg.rf.722231f398bcfe5b1323c52fac501640.jpg: ignoring corrupt image/label: image size (8, 18) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0025644_jpg.rf.a63e0580ba05933485eb5482ddee3e03.jpg: ignoring corrupt image/label: image size (8, 18) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0025644_jpg.rf.bff2a4eca7a3cdd757658ef4312b0d68.jpg: ignoring corrupt image/label: image size (8, 18) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0025644_jpg.rf.ebc76e0283b24a45ece39c708d125761.jpg: ignoring corrupt image/label: image size (8, 18) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0026625_jpg.rf.5b54206d7399099ceb80f9cdbe31008f.jpg: ignoring corrupt image/label: image size (3, 2) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0026625_jpg.rf.dc6074c2d4da1b82bc0fdd917f0b4d62.jpg: ignoring corrupt image/label: image size (2, 3) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0027846_jpg.rf.aedbc10db9b239a031549f521d0a3f27.jpg: ignoring corrupt image/label: image size (8, 6) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0027846_jpg.rf.de6cecaf694e9234b2319fc55339719d.jpg: ignoring corrupt image/label: image size (8, 6) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0027846_jpg.rf.f5bcdeb7050be78fc5593fe89e8c829d.jpg: ignoring corrupt image/label: image size (6, 8) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0027846_jpg.rf.fb8aa7f053bcd0d77e9ddaa9dc9aa15c.jpg: ignoring corrupt image/label: image size (6, 8) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0027896_jpg.rf.13ba68e1359f7ddadc708f7721270dc8.jpg: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0027896_jpg.rf.54da1d90f5c31198de376d1d416e57f6.jpg: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0027915_jpg.rf.1d2d1568400756fdc9eb8146d49bc725.jpg: ignoring corrupt image/label: image size (8, 13) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0027915_jpg.rf.39b1de382abe9738fe9cb721362b0a7b.jpg: ignoring corrupt image/label: image size (46, 8) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0027915_jpg.rf.4e47720ed338a8656110164ff427ef08.jpg: ignoring corrupt image/label: image size (8, 13) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0027915_jpg.rf.af34cfd21480224902bbd18fa5bd4016.jpg: ignoring corrupt image/label: image size (46, 8) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0029123_jpg.rf.6f396b5938cc85aa64182614ede787f4.jpg: ignoring corrupt image/label: image size (14, 8) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0029123_jpg.rf.eb0b73e98379c8e4f70e72a4a3c5a6d9.jpg: ignoring corrupt image/label: image size (14, 8) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0029831_jpg.rf.791ccb314afb72c9cebb7e6aed39fddc.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     8.0445      8.8742]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0029831_jpg.rf.df4feae68e6d360e507657ce0b30a0d1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     7.9679      8.0445]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0030352_jpg.rf.41728a8ed5bc9a2a1ff4647e3e1e6b25.jpg: ignoring corrupt image/label: image size (8, 10) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/train/images/ISIC_0030352_jpg.rf.c5e090def1623340ecea2a69e50f974e.jpg: ignoring corrupt image/label: image size (8, 10) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (6.1GB ram): 100% 12964/12964 [00:53<00:00, 241.29it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/Skin-Cancer-Detection-2/valid/labels.cache... 2229 images, 0 backgrounds, 5 corrupt: 100% 2233/2233 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/valid/images/ISIC_0000229_jpg.rf.792d5ddd68a440375705b0a362ea1534.jpg: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/valid/images/ISIC_0000236_jpg.rf.21fa124db9dd6759394bd8affc9ace8c.jpg: ignoring corrupt image/label: image size (9, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/valid/images/ISIC_0000241_jpg.rf.78103ae1f85a8cf6bce0c6d65b288c00.jpg: ignoring corrupt image/label: image size (4, 3) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/valid/images/ISIC_0000381_jpg.rf.1f6c06a85a1f84c085c808a7a6734709.jpg: ignoring corrupt image/label: image size (4, 3) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/yolov5/Skin-Cancer-Detection-2/valid/images/ISIC_0027615_jpg.rf.4a98776a128dff40003474957f4a0716.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     4.3769           6      1.0052]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (1.0GB ram): 100% 2228/2228 [00:19<00:00, 114.64it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.26 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/yolov5s_results2/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov5s_results2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/49      1.68G    0.09797     0.0165    0.03575          7        416: 100% 811/811 [02:23<00:00,  5.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:21<00:00,  3.31it/s]\n",
            "                   all       2228       2228     0.0256      0.345     0.0704     0.0323\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/49      1.98G     0.0725     0.0164    0.02716          5        416: 100% 811/811 [02:14<00:00,  6.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.66it/s]\n",
            "                   all       2228       2228     0.0387      0.515      0.448      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/49         2G    0.06605    0.01431     0.0265          6        416: 100% 811/811 [02:14<00:00,  6.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:21<00:00,  3.24it/s]\n",
            "                   all       2228       2228      0.956       0.27      0.488      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/49         2G    0.06061    0.01313    0.02626          8        416: 100% 811/811 [02:10<00:00,  6.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.76it/s]\n",
            "                   all       2228       2228      0.995      0.337      0.558      0.471\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/49         2G    0.05583    0.01228    0.02617          3        416: 100% 811/811 [02:12<00:00,  6.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.78it/s]\n",
            "                   all       2228       2228      0.951      0.269      0.612      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/49         2G    0.05358    0.01154    0.02594          4        416: 100% 811/811 [02:12<00:00,  6.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.74it/s]\n",
            "                   all       2228       2228      0.957      0.363      0.603      0.459\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/49         2G    0.05188    0.01112    0.02603          8        416: 100% 811/811 [02:12<00:00,  6.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:20<00:00,  3.47it/s]\n",
            "                   all       2228       2228      0.983      0.339      0.652      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/49         2G    0.05035    0.01089    0.02579          3        416: 100% 811/811 [02:15<00:00,  5.97it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.62it/s]\n",
            "                   all       2228       2228      0.983      0.316      0.652      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/49         2G    0.04979    0.01079    0.02598         11        416: 100% 811/811 [02:13<00:00,  6.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.54it/s]\n",
            "                   all       2228       2228      0.994      0.349      0.698      0.578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/49         2G    0.04813     0.0104    0.02556          7        416: 100% 811/811 [02:09<00:00,  6.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.68it/s]\n",
            "                   all       2228       2228       0.99      0.356      0.637       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/49         2G    0.04782    0.01029    0.02525          8        416: 100% 811/811 [02:13<00:00,  6.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.70it/s]\n",
            "                   all       2228       2228      0.988      0.328      0.628      0.533\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/49         2G     0.0473    0.01017    0.02544          5        416: 100% 811/811 [02:12<00:00,  6.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:20<00:00,  3.38it/s]\n",
            "                   all       2228       2228      0.987      0.335      0.726      0.581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/49         2G    0.04678    0.01001     0.0253          7        416: 100% 811/811 [02:09<00:00,  6.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:23<00:00,  3.02it/s]\n",
            "                   all       2228       2228      0.984      0.284      0.752      0.581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/49         2G    0.04655    0.01002    0.02497          4        416: 100% 811/811 [02:07<00:00,  6.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.78it/s]\n",
            "                   all       2228       2228      0.977      0.309      0.638      0.549\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/49         2G      0.046   0.009868     0.0251          2        416: 100% 811/811 [02:10<00:00,  6.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:20<00:00,  3.47it/s]\n",
            "                   all       2228       2228      0.994      0.323      0.721      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/49         2G    0.04533   0.009808    0.02459          6        416: 100% 811/811 [02:11<00:00,  6.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.69it/s]\n",
            "                   all       2228       2228      0.985      0.355      0.696      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/49         2G    0.04517   0.009656    0.02454          6        416: 100% 811/811 [02:08<00:00,  6.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:20<00:00,  3.42it/s]\n",
            "                   all       2228       2228      0.994      0.287      0.864      0.659\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/49         2G    0.04468   0.009536     0.0244          4        416: 100% 811/811 [02:12<00:00,  6.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.73it/s]\n",
            "                   all       2228       2228      0.991      0.295      0.812      0.645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/49         2G    0.04424   0.009461    0.02388          4        416: 100% 811/811 [02:14<00:00,  6.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.58it/s]\n",
            "                   all       2228       2228      0.989      0.276      0.793       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/49         2G    0.04384    0.00951    0.02352         11        416: 100% 811/811 [02:07<00:00,  6.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.52it/s]\n",
            "                   all       2228       2228      0.993      0.271      0.783      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/49         2G     0.0432   0.009488    0.02341          8        416: 100% 811/811 [02:14<00:00,  6.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.51it/s]\n",
            "                   all       2228       2228      0.998       0.27      0.664      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/49         2G    0.04302   0.009422    0.02309          5        416: 100% 811/811 [02:10<00:00,  6.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.63it/s]\n",
            "                   all       2228       2228      0.952      0.249       0.68      0.555\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/49         2G     0.0425   0.009337    0.02261         10        416: 100% 811/811 [02:09<00:00,  6.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:21<00:00,  3.24it/s]\n",
            "                   all       2228       2228      0.988      0.269      0.646      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/49         2G    0.04244   0.009245    0.02216          8        416: 100% 811/811 [02:07<00:00,  6.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.72it/s]\n",
            "                   all       2228       2228      0.998      0.248      0.794      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/49         2G    0.04185   0.009077    0.02197          7        416: 100% 811/811 [02:14<00:00,  6.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.56it/s]\n",
            "                   all       2228       2228      0.992       0.27      0.789      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/49         2G    0.04137   0.009146    0.02167          7        416: 100% 811/811 [02:13<00:00,  6.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:20<00:00,  3.40it/s]\n",
            "                   all       2228       2228      0.978      0.282      0.833      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/49         2G    0.04136   0.009188    0.02153          9        416: 100% 811/811 [02:10<00:00,  6.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.76it/s]\n",
            "                   all       2228       2228      0.991      0.257      0.745      0.585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/49         2G    0.04087   0.009085      0.021          6        416: 100% 811/811 [02:12<00:00,  6.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.55it/s]\n",
            "                   all       2228       2228       0.99      0.277      0.785      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/49         2G    0.04009   0.008879    0.02078          6        416: 100% 811/811 [02:15<00:00,  6.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.64it/s]\n",
            "                   all       2228       2228      0.994      0.285      0.849      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/49         2G     0.0398   0.008874    0.02009          8        416: 100% 811/811 [02:09<00:00,  6.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:22<00:00,  3.15it/s]\n",
            "                   all       2228       2228      0.995      0.285      0.758      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/49         2G    0.03957   0.008812    0.02001          6        416: 100% 811/811 [02:08<00:00,  6.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.54it/s]\n",
            "                   all       2228       2228      0.971      0.229      0.733      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/49         2G    0.03962   0.008759    0.01976          4        416: 100% 811/811 [02:13<00:00,  6.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.54it/s]\n",
            "                   all       2228       2228      0.995      0.264      0.795      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/49         2G    0.03902   0.008686    0.01941          4        416: 100% 811/811 [02:09<00:00,  6.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.56it/s]\n",
            "                   all       2228       2228      0.975       0.25      0.774      0.627\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/49         2G    0.03803   0.008672    0.01855          3        416: 100% 811/811 [02:10<00:00,  6.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:20<00:00,  3.43it/s]\n",
            "                   all       2228       2228      0.982      0.249      0.831      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/49         2G    0.03817   0.008571     0.0189          9        416: 100% 811/811 [02:11<00:00,  6.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:20<00:00,  3.50it/s]\n",
            "                   all       2228       2228      0.962      0.248      0.818      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/49         2G    0.03782   0.008459    0.01877          7        416: 100% 811/811 [02:12<00:00,  6.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.64it/s]\n",
            "                   all       2228       2228       0.97      0.235      0.809      0.627\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/49         2G    0.03771    0.00851    0.01838          3        416: 100% 811/811 [02:10<00:00,  6.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.54it/s]\n",
            "                   all       2228       2228      0.992      0.236      0.776      0.648\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/49         2G    0.03716   0.008317    0.01818          7        416: 100% 811/811 [02:09<00:00,  6.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.60it/s]\n",
            "                   all       2228       2228      0.993      0.251      0.717      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/49         2G    0.03665   0.008312    0.01802          5        416: 100% 811/811 [02:11<00:00,  6.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.56it/s]\n",
            "                   all       2228       2228      0.967      0.235      0.796      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/49         2G     0.0364   0.008114    0.01769          4        416: 100% 811/811 [02:12<00:00,  6.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:20<00:00,  3.49it/s]\n",
            "                   all       2228       2228      0.994       0.23      0.837      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/49         2G     0.0362   0.008146    0.01757          8        416: 100% 811/811 [02:12<00:00,  6.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.79it/s]\n",
            "                   all       2228       2228       0.99      0.227      0.834      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/49         2G    0.03509   0.008042    0.01715          6        416: 100% 811/811 [02:05<00:00,  6.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.72it/s]\n",
            "                   all       2228       2228      0.993      0.251      0.816      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/49         2G    0.03536   0.008062    0.01716          5        416: 100% 811/811 [02:08<00:00,  6.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.64it/s]\n",
            "                   all       2228       2228      0.991       0.24      0.798      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/49         2G    0.03506   0.007918      0.017          8        416: 100% 811/811 [02:11<00:00,  6.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.71it/s]\n",
            "                   all       2228       2228      0.993      0.251      0.779      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/49         2G    0.03477   0.008027    0.01695          9        416: 100% 811/811 [02:13<00:00,  6.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.56it/s]\n",
            "                   all       2228       2228      0.992      0.231      0.791      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/49         2G    0.03415   0.007861    0.01674         10        416: 100% 811/811 [02:10<00:00,  6.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:18<00:00,  3.75it/s]\n",
            "                   all       2228       2228      0.993      0.228      0.757      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/49         2G    0.03428   0.007815    0.01677          5        416: 100% 811/811 [02:10<00:00,  6.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.57it/s]\n",
            "                   all       2228       2228      0.994      0.232       0.86      0.664\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/49         2G    0.03328   0.007638    0.01588          8        416: 100% 811/811 [02:10<00:00,  6.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.58it/s]\n",
            "                   all       2228       2228      0.994      0.208       0.85      0.655\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/49         2G    0.03344   0.007606    0.01603          7        416: 100% 811/811 [02:11<00:00,  6.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:19<00:00,  3.68it/s]\n",
            "                   all       2228       2228      0.994      0.225        0.8      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/49         2G    0.03354   0.007595    0.01612          5        416: 100% 811/811 [02:13<00:00,  6.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:20<00:00,  3.39it/s]\n",
            "                   all       2228       2228      0.993      0.239      0.817      0.632\n",
            "\n",
            "50 epochs completed in 2.141 hours.\n",
            "Optimizer stripped from runs/train/yolov5s_results2/weights/last.pt, 14.8MB\n",
            "Optimizer stripped from runs/train/yolov5s_results2/weights/best.pt, 14.8MB\n",
            "\n",
            "Validating runs/train/yolov5s_results2/weights/best.pt...\n",
            "Fusing layers... \n",
            "custom_YOLOv5s summary: 182 layers, 7254609 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 70/70 [00:23<00:00,  2.99it/s]\n",
            "                   all       2228       2228      0.993      0.232       0.86      0.663\n",
            "                 nevus       2228       2228      0.993      0.232       0.86      0.663\n",
            "Results saved to \u001b[1mruns/train/yolov5s_results2\u001b[0m\n",
            "CPU times: user 1min 25s, sys: 9.17 s, total: 1min 35s\n",
            "Wall time: 2h 10min 55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/yolov5/runs/train/yolov5s_results2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVw0lBIBl3IF",
        "outputId": "4ec4a895-d65e-4228-c4ec-4732388a70fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix.png\t\t\t\t    PR_curve.png\t   val_batch0_pred.jpg\n",
            "events.out.tfevents.1720776758.15e020823460.6067.0  R_curve.png\t\t   val_batch1_labels.jpg\n",
            "F1_curve.png\t\t\t\t\t    results.csv\t\t   val_batch1_pred.jpg\n",
            "hyp.yaml\t\t\t\t\t    results.png\t\t   val_batch2_labels.jpg\n",
            "labels_correlogram.jpg\t\t\t\t    train_batch0.jpg\t   val_batch2_pred.jpg\n",
            "labels.jpg\t\t\t\t\t    train_batch1.jpg\t   weights\n",
            "opt.yaml\t\t\t\t\t    train_batch2.jpg\n",
            "P_curve.png\t\t\t\t\t    val_batch0_labels.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CLl5_WO17lqY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}